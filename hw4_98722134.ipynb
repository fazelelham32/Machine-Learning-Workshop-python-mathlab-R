{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nUXoMKBNL2BB"
   },
   "source": [
    "\n",
    "<h3 align=\"center\">به نام خدا </h3>\n",
    "<h2 align=\"center\">تمرین سری چهارم </h2>\n",
    "\n",
    "\n",
    "<p align=\"right\">در این تمرین می خواهیم با کمک دانسته های خود از توزیع نرمال یک متغیره یک دسته بند طراحی کنیم</p>\n",
    "\n",
    "<p align=\"right\">برای پیاده سازی مدل ها از کتابخانه  استفاده کنید scikitlearn</p>\n",
    "\n",
    "<p align=\"right\">https://scikit-learn.org/stable/</p>\n",
    "\n",
    "<p align=\"center\">Taha Samavati - 98722134</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UzYY1KuUPu2Z"
   },
   "source": [
    "# خواندن داده ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0v0tV8s9P4xZ"
   },
   "source": [
    "<p align=\"right\">ابتدا داده ها را از کتابخانه می خوانیم و سپس داده ها را به دو دسته ی آموزش و آزمایش تقسیم بندی می کنیم</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "3wyhQpoQQgQ0",
    "outputId": "8f4cdba2-a3f2-4f35-cada-696f1d225c17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our dataset has 4 features. for more information about data surf the web\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# store the feature matrix (X) and response vector (y) \n",
    "X = iris.data\n",
    "y = iris.target\n",
    "print(\"our dataset has \" + str(X.shape[1]) + \" features. for more information about data surf the web\")\n",
    "# splitting X and y into training and testing sets\n",
    "#you can change the test size, fit model with more or less data and see results\n",
    "from sklearn.model_selection import train_test_split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fq4rKK30R9fz"
   },
   "source": [
    "### q1) print the number of train and test data and number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RQy7kw4pSR8l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of train data is : 90\n",
      "the number of test data is : 60\n",
      "there are 3 different classes in the dataset\n"
     ]
    }
   ],
   "source": [
    "print(\"the number of train data is : \" + str(X_train.shape[0]))\n",
    "print(\"the number of test data is : \" + str(X_test.shape[0]))\n",
    "print(\"there are \" + str(len(set(y_train))) + \" different classes in the dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GDB-hbPVSpHt"
   },
   "source": [
    "# آموزش یک مدل با فرض گوسی بودن توزیع داد ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nqd2cq44Tksm"
   },
   "source": [
    "<p align=\"right\">فرض کنید می دانیم که داده های ما از یک توزیع گوسی پیروی می کنند و همچنین ویژگی ها از هم مستقل هستند لطفا با کمک فرض های مساله و بدون کمک از مدل های آماده یک مدل برای دسته بندی کلاس ها آموزش دهید . دقت کنید که نباید از کدهای آماده استفاده کنید و فقط مجاز هستید برای فرمول های پایه مثل میانگین یا واریانس از توابع آماده استفاده نمایید</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yAlhGi06Voxt"
   },
   "outputs": [],
   "source": [
    "# training the model on training set \n",
    "\n",
    "# write your code here :\n",
    "# Naive Bayes model implementation\n",
    "class Bayes():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.priors = None\n",
    "        self.distribution_params = None\n",
    "    \n",
    "    def gaussian(self,x,u,var):\n",
    "        return (1/np.sqrt(2*np.pi*var)) * np.exp(-((x-u)**2)/(2*var))\n",
    "    \n",
    "    def _compute_priors(self,yt):\n",
    "\n",
    "        classes = np.unique(yt)\n",
    "        targets = np.asarray(yt)\n",
    "        self.num_classes = (len(classes))\n",
    "        # compute prior probabilities\n",
    "        priors = np.zeros((len(classes),))\n",
    "        for i in range(len(classes)):\n",
    "            priors[i] = yt[yt==classes[i]].shape[0]/targets.shape[0]\n",
    "\n",
    "        return priors\n",
    "\n",
    "    def _estimate_pdf_dist(self, xt,yt):\n",
    "        classes = np.unique(yt)\n",
    "        targets = np.asarray(yt)\n",
    "        distribution_params = np.zeros((len(classes),xt.shape[1],2))\n",
    "        # compute class conditional pdfs\n",
    "        for i in range(len(classes)):\n",
    "            x = xt[yt==classes[i]]\n",
    "            for j in range(x.shape[1]):\n",
    "                distribution_params[i,j,0] = np.mean(x[:,j])\n",
    "                distribution_params[i,j,1] = np.var(x[:,j])\n",
    "        return distribution_params\n",
    "    \n",
    "    def train(self,xt,yt):\n",
    "        self.priors = self._compute_priors(yt)\n",
    "        self.distribution_params = self._estimate_pdf_dist(xt,yt)\n",
    "\n",
    "    def predict(self,sample):\n",
    "        # compute posterior probabilities\n",
    "        posteriors = np.zeros((self.num_classes,))\n",
    "        for i in range(self.num_classes):\n",
    "            likelihoods = np.asarray([self.gaussian(x,u,var) for x,u,var in zip(sample,self.distribution_params[i,:,0],self.distribution_params[i,:,1]) ])\n",
    "            posteriors[i] = self.priors[i]* np.prod(likelihoods)\n",
    "        # return argument of maximum posterior\n",
    "        return np.argmax(posteriors)\n",
    "\n",
    "\n",
    "model = Bayes()\n",
    "model.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wkv9HCmSWAk0"
   },
   "source": [
    "<p align=\"right\">اکنون با کمک داده های آزمایشی دقت مدل خود را بسنجید</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ordqnzrKXcLA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:95.08  Recall:95.0  F1-score:95.0\n"
     ]
    }
   ],
   "source": [
    "#write your code here :\n",
    "predictions = []\n",
    "for i in range(X_test.shape[0]):\n",
    "    predictions.append(model.predict(X_test[i,:]))\n",
    "    \n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"  Recall:\"+str(round(rcall*100,2))+\"  F1-score:\"+str(round(f1*100,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9V49EZ73XsvG"
   },
   "source": [
    "# آموزش مدل بدون دانستن توزیع داده ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uni-0aA_X1ac"
   },
   "source": [
    "<p align=\"right\">داده ها را با کمک دسته بند اس وی ام و همچنین یک شبکه عصبی ساده دسته بندی کنید و دقت را با بخش قبل مقایسه نمایید</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VftAlrbXZ-Nn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:98.41%  Recall:98.33%  F1-score:98.33%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#train svm model\n",
    "#write yor code here :\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train,y_train)\n",
    "# predict\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# evaluate performance\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RYJlUDsGaGQT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:100.0%  Recall:100.0%  F1-score:100.0%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#use two hidden layers \n",
    "#train multi layer perceptron\n",
    "#write yor code here :\n",
    "neural_model = MLPClassifier(hidden_layer_sizes=(256,100 ), activation='logistic',max_iter=1000)\n",
    "neural_model.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predictions = neural_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Precision of implemented Naive bayes on test-set is 95 % \n",
    "* The Precision of SVM classifier is better with 98.4%\n",
    "* The Best precision is achieved with neural network model 100%\n",
    "\n",
    "* **The precision of the implemented Gaussian Naive Bayes model is lower than other trained model because we naively assumed the data has gaussian distribution.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J_bh4KyklqFA"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yYGlkDuckgmz"
   },
   "source": [
    "# خواندن داده های جدید"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d626_2ecknMc"
   },
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "# store the feature matrix (X) and response vector (y) \n",
    "X = wine.data \n",
    "y = wine.target \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E3ihimJ_lBJq"
   },
   "source": [
    "# آموزش یک مدل با فرض گوسی بودن توزیع داد ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EIbuPy6GlKyw"
   },
   "source": [
    "<p align=\"right\">فرض کنید می دانیم که داده های ما از یک توزیع گوسی پیروی می کنند با کمک کتابخانه های آماده یک مدل برای دسته بندی کلاس ها آموزش دهید می  توانید برای این قسمت از کتابخانه های آماده نیز استفاده کنید و نیازی به پیاده سازی نیست</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2i8GbQt9lPJO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "# training the model on training set \n",
    "\n",
    "# write your code here :\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9ugDovFDljq2"
   },
   "source": [
    "<p align=\"right\">اکنون با کمک داده های آزمایشی دقت مدل خود را بسنجید</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnkJltLll0qD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:98.66%  Recall:98.61%  F1-score:98.61%\n"
     ]
    }
   ],
   "source": [
    "#write your code here :\n",
    "predictions = gnb.predict(X_test)\n",
    "\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "24nscd6El30c"
   },
   "source": [
    "# آموزش مدل بدون دانستن توزیع داده ها"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jXoB6ppJl7Vl"
   },
   "source": [
    "<p align=\"right\">داده ها را با کمک دسته بند اس وی ام و همچنین یک شبکه عصبی ساده دسته بندی کنید و دقت را با بخش قبل مقایسه نمایید</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9cw27u1bmBWE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:70.0%  Recall:70.83%  F1-score:69.76%\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "#train svm model\n",
    "#write yor code here :\n",
    "svm_model = svm.SVC()\n",
    "svm_model.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predictions = svm_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqS7kFEqmEMG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:94.74%  Recall:94.44%  F1-score:94.42%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "#train multi layer perceptron\n",
    "#write yor code here :\n",
    "neural_model = MLPClassifier(hidden_layer_sizes=(256,100 ), activation='logistic',max_iter=1000)\n",
    "neural_model.fit(X_train,y_train)\n",
    "\n",
    "# predict\n",
    "predictions = neural_model.predict(X_test)\n",
    "\n",
    "# evaluate\n",
    "\n",
    "prec,rcall,f1,_ = precision_recall_fscore_support(y_test, predictions,average = 'weighted')\n",
    "print(\"Precision:\"+str(round(prec*100,2))+\"%  Recall:\"+str(round(rcall*100,2))+\"%  F1-score:\"+str(round(f1*100,2))+\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The Precision of GaussianNaiveBayes on test-set is 98.7 % \n",
    "* The Precision of SVM classifier is lower with 70.0%\n",
    "* The Neural net precision is 94.74%\n",
    "-----------------------------------------------\n",
    "* The precision of the Gaussian Naive Bayes model is Better than other trained models\n",
    "* **this shows that the data really has a gaussian like distribution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xw54ZdjmlsjN"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X_qYfi-kgFbN"
   },
   "source": [
    "#بخش امتیازی"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NQ97VUicmoir"
   },
   "source": [
    "<p align=\"right\">آیا راهی وجود دارد که قبل از انتخاب بک دسته بند بتوان توزیع یک داده را حدس زد و دسته بندی را بر اساس این بینش از داده ها انجام داد؟</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Oi6thGwnNiC"
   },
   "source": [
    "* **The simplest way is to plot the data but this method can't help a lot.**\n",
    "* **Another way is to use distribution tests such as \"the Anderson-Darling test\"**\n",
    "* **These tests yield a p-value and if it's lower than some value we can reject the null hypothesis and conclude that our data doesn't have that special distribution, So we try other distributions to find one with high p-value.**"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "hw4-project",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
